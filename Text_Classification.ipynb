{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np \n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle \n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = load_files(\"txt_sentoken/\")\n",
    "\n",
    "X, y = dataset.data , dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the X, y as a pickle file to reduce the size of the file \n",
    "\n",
    "with open('X.pickle','wb') as f:\n",
    "    pickle.dump(X,f)\n",
    "\n",
    "with open('y.pickle','wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickeling the dataset \n",
    "del X\n",
    "del y\n",
    "\n",
    "with open('X.pickle','rb') as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open('y.pickle','rb') as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing \n",
    "\n",
    "# Creating the corpus\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    review = re.sub(r'\\W', ' ', str(X[i]))\n",
    "    review = review.lower()\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ', review)\n",
    "    review = re.sub(r'^[a-z]\\s+', ' ', review)\n",
    "    review = re.sub(r'\\s+',' ', review)\n",
    "    corpus.append(review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.feature_extraction.text import CountVectorizer \\n\\nvectorizer = CountVectorizer(max_features= 2000,min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\\nX = vectorizer.fit_transform(corpus).toarray()\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vectorizer = CountVectorizer(max_features= 2000,min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(corpus).toarray()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_extraction.text import TfidfTransformer \\n\\ntransformer = TfidfTransformer()\\nX = transformer.fit_transform(X).toarray()'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.feature_extraction.text import TfidfTransformer \n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "X = transformer.fit_transform(X).toarray()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the above two seperate steps as Count vectroizer followed by Tfidf transformer or in a single step like below\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features= 2000,min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "prediction = accuracy_score(y_test, y_pred)\n",
    "\n",
    "prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picikiling the model for further use \n",
    "\n",
    "with open('clf.pickle','wb') as f:\n",
    "    pickle.dump(clf,f)\n",
    "    \n",
    "with open('TfidfTransformer.pickle','wb') as f:\n",
    "    pickle.dump(vectorizer,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a positive review\n"
     ]
    }
   ],
   "source": [
    "# Unpickiling the classifier and the tfifd model \n",
    "\n",
    "with open('clf.pickle','rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "with open('TfidfTransformer.pickle','rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "    \n",
    "    \n",
    "sample = ['I love this world']\n",
    "\n",
    "sample = tfidf.transform(sample).toarray()\n",
    "\n",
    "if clf.predict(sample)[0] == 1:\n",
    "    print('It is a positive review')\n",
    "else:\n",
    "    print('It is a negative review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy \n",
    "import re \n",
    "import pickle\n",
    "\n",
    "from tweepy import OAuthHandler \n",
    "\n",
    "consumer_key  = \"your key\"\n",
    "consumer_secret = \"your key\"\n",
    "access_token = \"your key\"\n",
    "access_secret = \"your key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "args = ['facebook']\n",
    "\n",
    "api = tweepy.API(auth, timeout = 10)\n",
    "\n",
    "tweet_list = []\n",
    "\n",
    "query = args[0]\n",
    "for status in tweepy.Cursor(api.search , q= query+\" -filter:retweets\", lang = 'en', result_type = \"recent\").items(100):\n",
    "    tweet_list.append(status.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_corpus = []\n",
    "\n",
    "for i in tweet_list:\n",
    "    review = re.sub(r'^https://t.co/[a-zA-Z0-9]*\\s',' ',i)\n",
    "    review = re.sub(r'\\s+https://t.co/[a-zA-Z0-9]*\\s',' ',review)\n",
    "    review = re.sub(r'\\s+https://t.co/[a-zA-Z0-9]*$',' ',review)\n",
    "    review = review.lower()\n",
    "    review = re.sub(r\"what's\", \"what is\", review)\n",
    "    review = re.sub(r\"that's\", \"that is\", review)\n",
    "    review = re.sub(r\"which's\", \"which is\", review)\n",
    "    review = re.sub(r\"she's\", \"she is\", review)\n",
    "    review = re.sub(r\"he's\", \"he is\", review)\n",
    "    review = re.sub(r\"they're\", \"they are\", review)\n",
    "    review = re.sub(r\"who're\", \"who are\", review)\n",
    "    review = re.sub(r\"we're\", \"we are\", review)\n",
    "    review = re.sub(r'\\W', ' ', review)\n",
    "    review = re.sub(r'\\d',' ', review)\n",
    "    review = re.sub(r'\\s+[a-z]\\s+', ' ', review)\n",
    "    review = re.sub(r'^[a-z]\\s+', ' ', review)\n",
    "    review = re.sub(r'\\s+[a-z]$',' ', review)\n",
    "    review = re.sub(r'\\s+',' ', review)\n",
    "    tweet_corpus.append(review)\n",
    "    #sentence = clf.predict(tfidf.transform([review]).toarray())[0]\n",
    "   # print(review,\":\",sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickiling the classifier and the tfifd model \n",
    "\n",
    "with open('clf.pickle','rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "    \n",
    "with open('TfidfTransformer.pickle','rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "tweets_analysis = []\n",
    "\n",
    "for i in tweet_corpus: \n",
    "    if clf.predict(tfidf.transform([i]).toarray())[0] == 1:\n",
    "        tweets_analysis.append('Positive')\n",
    "    else:\n",
    "        tweets_analysis.append('Negative')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweet_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing but success from my family henry ford ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rob batch nancy batchelder</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doesn want attention when grocery shopping</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>now playing skinnie gray ft crazy gwap like da...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min dotter</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>centristspokane cnbc cnbcmakeit agreed there ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>today indo aus wc match is similar to match be...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>go the distance pure imagination and you gott...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at hwy south church of christ</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>waiting on texas sunday blue laws to expire at...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tnmntdumpsta ll find the link hold on they sh...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>asies</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>checking out aladdin sm cinema mall of asia ma...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>people sharing other people engagement photos ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>real life</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>breeanavalles andrinnnnn timcast rubinreport ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>this still brings tears to my eyes they sure g...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>find out your family history in photos amp sto...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>happy puerto rican day parade nyc love you for...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>am nurse am pit bull dog owner am the majority</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dear facebook showing me larger thumbnails of ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>need to get busy and start doing this again</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>can my aunt stop posting pro life memes on fac...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>be petty towards my daddy side of the family ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>acting supervisor today so we are having part...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>got sneak peak st this ep last night we are in...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>taylor joseph</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>facebook find it very sad that you make setti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>terry just finished expanding their alaska pas...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>black people are so freaking talented</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>just posted photo on facebook https co mxiy r...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>just posted photo on facebook https co lnr hjov</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>galway fans fuming on facebook not sure what t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>the classic philly cheesesteak at chickie and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>go hard at charter fitness</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>find myself as the sexiest in sharee and not ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>facebook bans natural news health ranger respo...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>mis bebes tom amp collins</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>have</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>today around the world believers are celebrati...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>locked down what should say ll interpret this ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>viadosr hi viadosr we want to take more in de...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>someone said must stop dragging brothers there...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>somebody please play want to see your answers ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>this is family wish all many blessings congrat...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>seniors helping seniors southwest broward coun...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>working theory am developing for low growth c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>my colors are these</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>today marks the day that all my grandkids and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cryptojolie facebook don use either if the bi...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>audit finds evidence of google bias toward the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>at libbey bowl ojai california</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>so no one can beat rafael nadal at the french ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>latestnews consumer credit counseling service...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>if you are looking for story tonight friedgehn...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>holaaaa facebook whatsapp twitter instagram s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>royal is the truth amp my son</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tko fitness</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>anthony sprouse</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>photo courtesy mak tumang facebook account man...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets tweet_analysis\n",
       "0   nothing but success from my family henry ford ...       Positive\n",
       "1                         rob batch nancy batchelder        Positive\n",
       "2         doesn want attention when grocery shopping        Positive\n",
       "3   now playing skinnie gray ft crazy gwap like da...       Positive\n",
       "4                                         min dotter        Positive\n",
       "5    centristspokane cnbc cnbcmakeit agreed there ...       Positive\n",
       "6   today indo aus wc match is similar to match be...       Positive\n",
       "7    go the distance pure imagination and you gott...       Positive\n",
       "8                      at hwy south church of christ        Positive\n",
       "9   waiting on texas sunday blue laws to expire at...       Positive\n",
       "10   tnmntdumpsta ll find the link hold on they sh...       Positive\n",
       "11                                             asies        Positive\n",
       "12  checking out aladdin sm cinema mall of asia ma...       Positive\n",
       "13  people sharing other people engagement photos ...       Positive\n",
       "14                                         real life        Positive\n",
       "15   breeanavalles andrinnnnn timcast rubinreport ...       Positive\n",
       "16  this still brings tears to my eyes they sure g...       Positive\n",
       "17  find out your family history in photos amp sto...       Positive\n",
       "18  happy puerto rican day parade nyc love you for...       Positive\n",
       "19    am nurse am pit bull dog owner am the majority        Negative\n",
       "20  dear facebook showing me larger thumbnails of ...       Positive\n",
       "21       need to get busy and start doing this again        Negative\n",
       "22  can my aunt stop posting pro life memes on fac...       Positive\n",
       "23   be petty towards my daddy side of the family ...       Positive\n",
       "24   acting supervisor today so we are having part...       Positive\n",
       "25  got sneak peak st this ep last night we are in...       Positive\n",
       "26                                     taylor joseph        Negative\n",
       "27   facebook find it very sad that you make setti...       Positive\n",
       "28  terry just finished expanding their alaska pas...       Positive\n",
       "29             black people are so freaking talented        Positive\n",
       "..                                                ...            ...\n",
       "70   just posted photo on facebook https co mxiy r...       Positive\n",
       "71   just posted photo on facebook https co lnr hjov        Positive\n",
       "72  galway fans fuming on facebook not sure what t...       Positive\n",
       "73  the classic philly cheesesteak at chickie and ...       Positive\n",
       "74                        go hard at charter fitness        Negative\n",
       "75   find myself as the sexiest in sharee and not ...       Negative\n",
       "76  facebook bans natural news health ranger respo...       Positive\n",
       "77                         mis bebes tom amp collins        Positive\n",
       "78                                              have        Positive\n",
       "79  today around the world believers are celebrati...       Positive\n",
       "80  locked down what should say ll interpret this ...       Positive\n",
       "81   viadosr hi viadosr we want to take more in de...       Positive\n",
       "82  someone said must stop dragging brothers there...       Negative\n",
       "83  somebody please play want to see your answers ...       Negative\n",
       "84  this is family wish all many blessings congrat...       Positive\n",
       "85  seniors helping seniors southwest broward coun...       Positive\n",
       "86   working theory am developing for low growth c...       Positive\n",
       "87                               my colors are these        Positive\n",
       "88  today marks the day that all my grandkids and ...       Positive\n",
       "89   cryptojolie facebook don use either if the bi...       Negative\n",
       "90  audit finds evidence of google bias toward the...       Positive\n",
       "91                    at libbey bowl ojai california        Positive\n",
       "92  so no one can beat rafael nadal at the french ...       Positive\n",
       "93   latestnews consumer credit counseling service...       Negative\n",
       "94  if you are looking for story tonight friedgehn...       Negative\n",
       "95   holaaaa facebook whatsapp twitter instagram s...       Positive\n",
       "96                     royal is the truth amp my son        Positive\n",
       "97                                       tko fitness        Positive\n",
       "98                                   anthony sprouse        Positive\n",
       "99  photo courtesy mak tumang facebook account man...       Positive\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = {'tweets':tweet_corpus, 'tweet_analysis':tweets_analysis}\n",
    "tweet_sentiment_analysis = pd.DataFrame(df)\n",
    "\n",
    "\n",
    "tweet_sentiment_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
